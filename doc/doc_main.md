# Documentation ReadPicture

## üìã Vue d'ensemble

Application OCR pour la transcription de tableaux et documents en CSV.

**Architecture modulaire** :
- `main.py` : Point d'entr√©e
- `app/gui.py` : Interface graphique Tkinter
- `app/processors/` : Modules OCR et export

**Processors disponibles** :
- **TesseractProcessor** : OCR local gratuit
- **GoogleCloudProcessor** : OCR via Google Cloud Vision API (g√©n√©rique)
- **DocumentAIProcessor** : OCR via Google Document AI (sp√©cialis√© tableaux et documents structur√©s)
- **ChatGPTProcessor** : OCR via ChatGPT Vision (GPT-4o-mini, tr√®s performant pour tableaux complexes) ‚≠ê **RECOMMAND√â**

---

## üîß Architecture Processors

```
app/processors/
‚îú‚îÄ base_processor.py          # Classe abstraite
‚îú‚îÄ tesseract_processor.py     # OCR Tesseract
‚îú‚îÄ google_cloud_processor.py  # OCR Google Cloud Vision
‚îú‚îÄ document_ai_processor.py   # OCR Document AI (tableaux)
‚îú‚îÄ chatgpt_processor.py       # OCR ChatGPT Vision (‚≠ê performant)
‚îî‚îÄ export_processor.py        # Export CSV commun
```

### BaseProcessor (classe abstraite)

**M√©thodes √† impl√©menter** :
- `process_image(image_path) -> List[str]` : Extrait les lignes de texte
- `run(image_path, output_dir) -> Path` : Pipeline complet OCR + export CSV

### TesseractProcessor

**Pipeline process_image()** :
1. Chargement + redimensionnement si < 1000px
2. Pr√©traitement : grayscale ‚Üí CLAHE ‚Üí d√©bruitage ‚Üí binarisation (Otsu + Adaptive)
3. Test de 10 configs (5 PSM √ó 2 seuils)
4. S√©lection du meilleur r√©sultat (confiance max)
5. Retour des lignes de texte

**Configs Tesseract test√©es** :
- PSM 6 : Bloc de texte uniforme
- PSM 4 : Colonne unique
- PSM 3 : Page compl√®te auto
- PSM 11/12 : Page clairsem√©e

### GoogleCloudProcessor

**Pipeline process_image()** :
1. Chargement image en bytes
2. Appel API Google Cloud Vision (TEXT_DETECTION)
3. Extraction des lignes depuis la r√©ponse
4. Retour des lignes de texte

**Configuration requise** (dans `.env`) :
- `GOOGLE_CLOUD_API_KEY` : Cl√© API simple
- ou `GOOGLE_APPLICATION_CREDENTIALS` : Chemin vers JSON service account

### DocumentAIProcessor

**Pipeline process_image()** :
1. Chargement image en bytes + d√©tection type MIME
2. Appel API Document AI (processor configur√©)
3. Extraction du texte + structure du document
4. D√©tection optionnelle des tableaux
5. Retour des lignes de texte

**Avantages vs Cloud Vision** :
- Compr√©hension de la structure des documents
- Meilleure extraction de tableaux
- D√©tection des champs de formulaires
- Analyse de mise en page avanc√©e

**Configuration requise** (dans `.env`) :
- `GOOGLE_CLOUD_PROJECT_ID` : ID du projet Google Cloud (ex: 123456789012)
- `DOCUMENT_AI_PROCESSOR_ID` : ID du processor Document AI (ex: your_processor_id)
- `DOCUMENT_AI_LOCATION` : R√©gion du processor (ex: eu, us, asia)
- `GOOGLE_APPLICATION_CREDENTIALS` : Chemin vers JSON service account (OBLIGATOIRE pour Document AI)

### ChatGPTProcessor (‚≠ê RECOMMAND√â POUR TABLEAUX COMPLEXES)

**Pipeline process_image()** :
1. Chargement image ‚Üí conversion base64 PNG
2. Appel API ChatGPT (GPT-4o-mini avec vision)
3. Parsing et nettoyage du CSV retourn√©
4. Retour d'une structure List[List[str]] (tableau structur√©)

**Pipeline run()** :
1. process_image() ‚Üí r√©cup√®re le tableau structur√©
2. export_structured_to_csv() ‚Üí g√©n√®re le CSV final
3. Logs de tokens consomm√©s et co√ªt estim√©

**Avantages** :
- Excellente compr√©hension du contexte et de la structure
- G√©n√©ration directe de CSV bien format√©
- Pas de preprocessing n√©cessaire
- Tr√®s performant sur tableaux bancaires complexes

**Configuration requise** (dans `.env`) :
- `OPENAI_API_KEY` : Cl√© API OpenAI (ex: sk-proj-...)
- `COST_PER_1M_INPUT` (optionnel) : Co√ªt par 1M tokens input (d√©faut 0.60 USD)
- `COST_PER_1M_OUTPUT` (optionnel) : Co√ªt par 1M tokens output (d√©faut 2.40 USD)

### ExportProcessor (fonctions utilitaires)

**detect_columns(lines)** :
- D√©tecte automatiquement les colonnes (espaces multiples, tabs, patterns num√©riques)
- Normalise le nombre de colonnes

**export_to_csv(lines, dest_path, debug)** :
- Utilise detect_columns()
- Cr√©e un DataFrame pandas
- Export en CSV avec colonnes nomm√©es (Colonne_1, Colonne_2...)
- G√©n√®re un fichier .debug.txt si debug=True

---

## üñ•Ô∏è GUI (gui.py)

**Composants** :
- Radio buttons : S√©lection du processor (Tesseract / Google Cloud Vision / Document AI / ChatGPT Vision)
- Bouton "Choisir image(s)" : S√©lection multi-fichiers
- Liste des fichiers s√©lectionn√©s
- Bouton "Transcrire" : Lance le traitement
- Zone de logs : Affiche les r√©sultats

**Pipeline transcription** :
```
_on_transcribe()
‚îú‚îÄ> current_processor.run(image_path) pour chaque image
‚îú‚îÄ> Affichage des r√©sultats dans les logs
‚îî‚îÄ> MessageBox de confirmation
```

**Gestion des erreurs** :
- Si Google Cloud ou Document AI √©choue (credentials manquants) ‚Üí fallback automatique sur Tesseract
- Si package manquant (ImportError) ‚Üí fallback sur Tesseract avec message d'alerte
- Si NotImplementedError ‚Üí fallback sur Tesseract avec message d'alerte

---

## üöÄ Installation & Configuration

### 1. D√©pendances Python

```bash
pip install -r requirements.txt
```

**Packages** :
- opencv-python : Traitement d'image
- pytesseract : OCR Tesseract
- pillow : Manipulation d'images
- pandas : Export CSV
- python-dotenv : Gestion des variables d'environnement
- google-cloud-vision : API Google Cloud Vision
- google-cloud-documentai : API Google Document AI
- openai>=1.0 : API ChatGPT Vision

### 2. Tesseract OCR (requis)

**Windows** :
1. T√©l√©charger : https://github.com/UB-Mannheim/tesseract/wiki
2. Installer en cochant "Add to PATH"
3. Red√©marrer l'application

### 3. Google Document AI (recommand√© pour tableaux)

**Configuration obligatoire** :

1. **Cr√©er un processor Document AI** :
   - https://console.cloud.google.com/ai/document-ai
   - Create Processor ‚Üí "Document OCR"
   - Noter l'ID du processor (ex: your_processor_id) et la r√©gion (ex: eu)

2. **Cr√©er un Service Account** (obligatoire) :
   - https://console.cloud.google.com/iam-admin/serviceaccounts
   - Create Service Account ‚Üí Donner les permissions Document AI
   - Actions ‚Üí Manage Keys ‚Üí Add Key ‚Üí Create new key ‚Üí JSON
   - T√©l√©charger le fichier JSON

3. **Configurer le `.env`** :
```bash
GOOGLE_CLOUD_PROJECT_ID=your_project_id
DOCUMENT_AI_PROCESSOR_ID=your_processor_id
DOCUMENT_AI_LOCATION=eu
GOOGLE_APPLICATION_CREDENTIALS=C:\chemin\vers\service-account.json
```

### 4. Google Cloud Vision (optionnel)

Si tu veux aussi utiliser Cloud Vision pour de l'OCR g√©n√©rique :

**Option A : Cl√© API simple** :
1. https://console.cloud.google.com/ ‚Üí APIs & Services ‚Üí Credentials
2. Create Credentials ‚Üí API Key
3. Enable "Cloud Vision API"
4. Ajouter dans `.env` : `GOOGLE_CLOUD_API_KEY=votre_cl√©`

**Option B : Service Account JSON** :
- R√©utiliser le m√™me fichier JSON que Document AI

### 5. ChatGPT Vision (recommand√© pour tableaux complexes) ‚≠ê

**Configuration obligatoire** :

1. **Cr√©er une cl√© API OpenAI** :
   - https://platform.openai.com/api-keys
   - Create new secret key
   - Copier la cl√© (commen√ßant par sk-proj-... ou sk-...)

2. **Configurer le `.env`** :
```bash
OPENAI_API_KEY=sk-proj-votre_cl√©_ici
# Optionnel : personnaliser le calcul de co√ªt
COST_PER_1M_INPUT=0.60
COST_PER_1M_OUTPUT=2.40
```

**Mod√®le utilis√©** : `gpt-4o-mini` (vision)
**Co√ªts approximatifs** : ~0.60 USD / 1M tokens input, ~2.40 USD / 1M tokens output

### 6. Fichier .env

Le fichier `.env` peut contenir (selon les processors utilis√©s) :
```bash
# ChatGPT (recommand√©)
OPENAI_API_KEY=sk-proj-votre_cl√©

# Document AI (alternatif)
GOOGLE_CLOUD_PROJECT_ID=your_project_id
DOCUMENT_AI_PROCESSOR_ID=your_processor_id
DOCUMENT_AI_LOCATION=eu
GOOGLE_APPLICATION_CREDENTIALS=C:\chemin\vers\service-account.json

# Google Cloud Vision (optionnel)
GOOGLE_CLOUD_API_KEY=votre_cl√©
```

**Note** : Le fichier `.env` est dans `.gitignore` et ne doit JAMAIS √™tre commit√©.

---

## üìÇ Structure des fichiers

```
ReadPicture/
‚îú‚îÄ main.py                    # Point d'entr√©e
‚îú‚îÄ requirements.txt           # D√©pendances Python
‚îú‚îÄ .env                       # Configuration (non versionn√©)
‚îú‚îÄ .gitignore                 
‚îú‚îÄ app/
‚îÇ  ‚îú‚îÄ __init__.py             # Charge le .env au d√©marrage
‚îÇ  ‚îú‚îÄ gui.py                  # Interface graphique
‚îÇ  ‚îî‚îÄ processors/
‚îÇ     ‚îú‚îÄ __init__.py
‚îÇ     ‚îú‚îÄ base_processor.py
‚îÇ     ‚îú‚îÄ tesseract_processor.py
‚îÇ     ‚îú‚îÄ google_cloud_processor.py
‚îÇ     ‚îú‚îÄ document_ai_processor.py
‚îÇ     ‚îú‚îÄ chatgpt_processor.py
‚îÇ     ‚îî‚îÄ export_processor.py
‚îî‚îÄ doc/
   ‚îú‚îÄ doc_main.md             # Cette doc
   ‚îî‚îÄ last_modif.md           # Journal des modifications
```

---

## üîç Ajout d'un nouveau processor

1. Cr√©er `app/processors/mon_processor.py`
2. H√©riter de `BaseProcessor`
3. Impl√©menter `process_image()` et `run()`
4. Ajouter dans `app/processors/__init__.py`
5. Ajouter un radio button dans `gui.py`
6. Ajouter la logique dans `_update_processor()`

**Exemple** :
```python
from .base_processor import BaseProcessor
from .export_processor import export_to_csv

class MonProcessor(BaseProcessor):
    def process_image(self, image_path: Path) -> List[str]:
        # Votre logique OCR ici
        return lines
    
    def run(self, image_path: Path, output_dir: Path | None = None) -> Path:
        lines = self.process_image(image_path)
        csv_path = output_dir / f"{image_path.stem}.csv"
        export_to_csv(lines, csv_path, debug=self.debug)
        return csv_path
```

---

## üêõ Debug

**Mode debug activ√© par d√©faut** (`debug=True`) :

**Tesseract** g√©n√®re dans `debug/` :
- Images pr√©trait√©es (original, gray, otsu, adaptive)
- R√©sultats de chaque config test√©e (txt)

**Export CSV** g√©n√®re :
- `fichier.debug.txt` avec lignes brutes et structur√©es

**Logs** :
- Affichage console des r√©sultats de chaque config
- Confiance moyenne pour chaque test

---

## üìù TODO

- [x] Impl√©menter DocumentAIProcessor avec support Document AI
- [x] Impl√©menter ChatGPTProcessor avec support GPT-4o-mini Vision
- [ ] Tester Document AI vs ChatGPT sur vrais tableaux comptables
- [ ] Comparer les performances Tesseract vs Document AI vs ChatGPT
- [ ] Exploiter la d√©tection native de tableaux de Document AI (actuellement on utilise juste le texte)
- [ ] Impl√©menter GoogleCloudProcessor une fois les credentials disponibles
- [ ] Ajouter un processor Azure Computer Vision ?
- [ ] Optimiser la d√©tection de colonnes pour les tableaux complexes


